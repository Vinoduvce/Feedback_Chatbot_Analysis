{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in ./venv/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./venv/lib/python3.12/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/VI20463367/Documents/feedbackChatbot/venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement llama3.1 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for llama3.1\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/VI20463367/Documents/feedbackChatbot/venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ollama' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm\u001b[38;5;241m=\u001b[39m\u001b[43mOllama\u001b[49m(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ollama' is not defined"
     ]
    }
   ],
   "source": [
    "llm=Ollama(model='llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=Ollama(model='llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"what is ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VI20463367/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama (also spelled Olamá) is a popular traditional Mexican dish, specifically from the state of Guerrero. It's a type of meatball soup made with beef or pork, potatoes, onions, garlic, and various spices, simmered in a rich broth.\n",
      "\n",
      "The name \"ollama\" comes from the Nahuatl language, which was spoken by the Aztecs. In Nahuatl, \"olla\" means \"meatball\" and \"ma\" means \"water\" or \"broth\". So, Ollama literally translates to \"meatballs in broth\".\n",
      "\n",
      "This hearty soup is often served with warm tortillas, lime wedges, and a sprinkle of chopped cilantro. The rich flavors and tender meat make it a comforting and satisfying meal.\n",
      "\n",
      "Would you like some recipe suggestions or more information about Ollama's history and cultural significance?\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1=\"what is ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama!\n",
      "\n",
      "Ollama is a popular online tool that helps you create and share interactive stories, games, or presentations. It's often used by educators, students, and professionals to engage audiences in an immersive way.\n",
      "\n",
      "Here are some key features of Ollama:\n",
      "\n",
      "1. **Interactive storytelling**: Create stories with multiple paths, allowing users to make choices that affect the narrative.\n",
      "2. **Game-like experiences**: Design interactive games, quizzes, or challenges that can be shared with others.\n",
      "3. **Presentations**: Use Ollama to create engaging presentations that incorporate multimedia elements like images, videos, and audio.\n",
      "4. **Collaboration tools**: Invite others to collaborate on a project, and assign roles to ensure seamless teamwork.\n",
      "\n",
      "Ollama is a great tool for:\n",
      "\n",
      "* Teachers: Create interactive lessons, games, or quizzes to engage students and make learning fun.\n",
      "* Students: Develop projects that showcase your creativity and skills.\n",
      "* Professionals: Use Ollama to create engaging presentations, trainings, or marketing materials.\n",
      "\n",
      "If you're interested in exploring Ollama, I can provide more information on how to get started!\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "        format=\"\"\"Feedback question?\n",
    "                Select One:\n",
    "                        Very Effective\n",
    "                        Effective\n",
    "                        Neutral\n",
    "                        Ineffective\n",
    "                        Very Ineffective\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VI20463367/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "llm=Ollama(model='llama3',temperature=0.7)\n",
    "\n",
    "prompt=\"\"\"Candidate need to give feedback about the interview process, So generate 5 question to candidate based on {text}\n",
    "        feedback question is in the format of {format}\"\"\"\n",
    "\n",
    "feedback_question_generation=PromptTemplate(\n",
    "    input_variables=[\"text\",\"format\"],\n",
    "    template=prompt\n",
    ")\n",
    "\n",
    "feedback_question_chain=LLMChain(llm=llm,prompt=feedback_question_generation,output_key=\"feedback\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath=\"/Users/VI20463367/Documents/feedbackChatbot/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/VI20463367/Documents/feedbackChatbot/data.txt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath, 'r') as file:\n",
    "    TEXT = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInterviewer: Good morning, Jane. Thanks for coming in today. How are you?\\n\\nJane: Good morning! I’m doing well, thank you. I’m excited about this opportunity.\\n\\nInterviewer: Great to hear. Let’s get started. Can you tell me a little about your background and what led you to apply for this position?\\n\\nJane: Absolutely. I have a degree in Marketing from the University of Chicago and over five years of experience working as a marketing coordinator. In my previous role at ABC Corp, I was responsible for managing social media campaigns, analyzing market trends, and coordinating with the sales team. I’ve always admired your company’s innovative approach to marketing, and I’m particularly impressed by your recent campaign for the new product launch. That’s what motivated me to apply for this position.\\n\\nInterviewer: That’s great. We’re certainly proud of that campaign. Can you describe a challenging project you worked on and how you handled it?\\n\\nJane: Sure. One of the most challenging projects I worked on was a product rebranding initiative. We had a tight deadline and a limited budget. I coordinated with multiple teams, including design, content, and sales, to ensure everything was on track. We faced several setbacks, including delayed deliverables from the design team, but I facilitated extra meetings to get us back on schedule and reallocated some of our budget to address the delays. In the end, the rebrand was a success and led to a 20% increase in product sales over the next quarter.\\n\\nInterviewer: Impressive. It sounds like you handled the pressure well. How do you prioritize and manage your workload when dealing with multiple projects?\\n\\nJane: I use a combination of tools and techniques to manage my workload. I start by listing all my tasks and deadlines, then I use project management software to track progress and set reminders. I also prioritize tasks based on their urgency and impact. Regular check-ins with my team help ensure that we’re all aligned and that any issues are addressed promptly. Flexibility is key; if priorities shift, I adjust my plan accordingly.\\n\\nInterviewer: That’s a solid approach. Can you tell me about a time when you had to work with a difficult team member and how you handled the situation?\\n\\nJane: Certainly. At one point, I worked with a team member who was resistant to feedback and often missed deadlines. I approached the situation by having a candid one-on-one discussion with them to understand their perspective and identify any underlying issues. I also made sure to provide constructive feedback and offer support, such as additional training if needed. Over time, we were able to improve communication and collaboration, which ultimately led to better performance and a more cohesive team.\\n\\nInterviewer: It sounds like you have strong interpersonal skills. Finally, why do you think you’d be a good fit for this role?\\n\\nJane: I believe my background in marketing, combined with my experience in managing projects and working with cross-functional teams, aligns well with the requirements of this role. I’m passionate about creating impactful marketing strategies and am particularly excited about the opportunity to contribute to your team’s innovative projects. I’m also a fast learner and adapt quickly to new environments, which I think will help me integrate smoothly into your company.\\n\\nInterviewer: Thank you, Jane. This has been a great conversation. We’ll be in touch soon regarding the next steps.\\n\\nJane: Thank you for the opportunity. I look forward to hearing from you.\\n\\nInterviewer: Have a great day!\\n\\nJane: You too!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['format', 'text'], template='Candidate need to give feedback about the interview process, So generate 5 question to candidate based on {text}\\n        feedback question is in the format of {format}'), llm=Ollama(model='llama3', temperature=0.7), output_key='feedback')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback_question_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VI20463367/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 feedback questions based on the interview process:\n",
      "\n",
      "**Question 1:** How would you rate the overall effectiveness of the interview process?\n",
      "\n",
      "* Very Effective\n",
      "* Effective\n",
      "* Neutral\n",
      "* Ineffective\n",
      "* Very Ineffective\n",
      "\n",
      "**Question 2:** Were there any specific areas or topics that you felt were not adequately covered during the interview? If so, how could we improve?\n",
      "\n",
      "(Open-ended text field for candidate to provide feedback)\n",
      "\n",
      "**Question 3:** How would you rate the communication style and professionalism of the interviewer(s)?\n",
      "\n",
      "* Very Effective\n",
      "* Effective\n",
      "* Neutral\n",
      "* Ineffective\n",
      "* Very Ineffective\n",
      "\n",
      "**Question 4:** Were there any questions or topics that you felt were not well-prepared by the interviewer(s)? If so, how could we improve?\n",
      "\n",
      "(Open-ended text field for candidate to provide feedback)\n",
      "\n",
      "**Question 5:** Would you recommend this company and interview process to other candidates? Why or why not?\n",
      "\n",
      "* Yes\n",
      "* No\n",
      "* Maybe\n",
      "\n",
      "Note: These questions are designed to gather feedback on various aspects of the interview process, including communication style, preparation, and overall effectiveness.\n"
     ]
    }
   ],
   "source": [
    "result=feedback_question_chain.run({\"text\":TEXT,\"format\":format})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in ./venv/lib/python3.12/site-packages (0.2.10)\n",
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.12/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: langchain-ollama in ./venv/lib/python3.12/site-packages (0.1.0)\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.2.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (0.1.94)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain-ollama) (0.3.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./venv/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./venv/lib/python3.12/site-packages (from langchain<0.3.0,>=0.2.9->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./venv/lib/python3.12/site-packages (from ollama<1,>=0.3.0->langchain-ollama) (0.27.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/VI20463367/Documents/feedbackChatbot/venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-community faiss-cpu langchain-ollama tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"llama2\\\" not found, try pulling it first\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m docs \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n\u001b[1;32m     11\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OllamaEmbeddings()\n\u001b[0;32m---> 12\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(db\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mntotal)\n",
      "File \u001b[0;32m~/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_core/vectorstores/base.py:1058\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m   1056\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m   1057\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m-> 1058\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_community/vectorstores/faiss.py:930\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    911\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m    912\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 930\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[1;32m    932\u001b[0m         texts,\n\u001b[1;32m    933\u001b[0m         embeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    938\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_community/embeddings/ollama.py:211\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed documents using an Ollama deployed embedding model.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[0;32m--> 211\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstruction_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_community/embeddings/ollama.py:199\u001b[0m, in \u001b[0;36mOllamaEmbeddings._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_emb_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[0;32m~/Documents/feedbackChatbot/venv/lib/python3.12/site-packages/langchain_community/embeddings/ollama.py:173\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference API HTTP code: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;241m%\u001b[39m (res\u001b[38;5;241m.\u001b[39mstatus_code, res\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     t \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mjson()\n",
      "\u001b[0;31mValueError\u001b[0m: Error raised by inference API HTTP code: 404, {\"error\":\"model \\\"llama2\\\" not found, try pulling it first\"}"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"/Users/VI20463367/Documents/feedbackChatbot/data.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "embeddings = OllamaEmbeddings()\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "print(db.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "pip install -U langchain-community faiss-cpu langchain-openai tiktoken"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
